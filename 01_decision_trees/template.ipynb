{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe03edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: DÃ½rmundur Helgi\n",
    "# Date: 24.8.2023\n",
    "# Project: Assignment 1 - Decision Trees\n",
    "# Acknowledgements: \n",
    "#\n",
    "\n",
    "\n",
    "from typing import Union\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from tools import load_iris, split_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28f33d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.33333333]\n",
      "[0.25 0.   0.25 0.5 ]\n"
     ]
    }
   ],
   "source": [
    "# Part 1.1\n",
    "def prior(targets: np.ndarray, classes: list) -> np.ndarray:\n",
    "    '''\n",
    "    Calculate the prior probability of each class type\n",
    "    given a list of all targets and all class types\n",
    "    '''\n",
    "    probabilities = np.zeros(len(classes))\n",
    "    \n",
    "    for i, a_class in enumerate(classes):\n",
    "        for target in targets:\n",
    "            if target == a_class:\n",
    "                probabilities[i] += 1\n",
    "    return probabilities / len(targets)\n",
    "\n",
    "print(prior([0, 0, 1], [0, 1]))\n",
    "print(prior([0, 2, 3, 3], [0, 1, 2, 3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12386101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 60\n"
     ]
    }
   ],
   "source": [
    "# Part 1.2\n",
    "def split_data(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    split_feature_index: int,\n",
    "    theta: float\n",
    ") -> Union[tuple, tuple]:\n",
    "    '''\n",
    "    Split a dataset and targets into two seperate datasets\n",
    "    where data with split_feature < theta goes to 1 otherwise 2\n",
    "    '''\n",
    "    condition = features[:, split_feature_index] < theta\n",
    "    \n",
    "    features_1 = features[condition]\n",
    "    targets_1 = targets[condition]\n",
    "\n",
    "    features_2 = features[~condition]\n",
    "    targets_2 = targets[~condition]\n",
    "\n",
    "    return (features_1, targets_1), (features_2, targets_2)\n",
    "\n",
    "\n",
    "features, targets, classes = load_iris()\n",
    "(f_1, t_1), (f_2, t_2) = split_data(features, targets, 2, 4.65)\n",
    "print(len(f_1), len(f_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7808d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* The dataset contains 150 samples\n",
      "* Each sample has 4 features\n",
      "* The first sample has the features:\n",
      "[5.1 3.5 1.4 0.2] and belongs to the class 0\n",
      "* Each datapoint can belong to any of the following classes:\n",
      "[0, 1, 2]\n",
      "* The train set contains 135 samples\n",
      "* The test set contains 14 samples\n"
     ]
    }
   ],
   "source": [
    "def using_iris():\n",
    "    '''\n",
    "    Shows how load_iris works\n",
    "    '''\n",
    "    # 1. Load the Iris dataset:\n",
    "    features, targets, classes = load_iris()\n",
    "\n",
    "    [n, f_dim] = features.shape\n",
    "\n",
    "    print(f'* The dataset contains {n} samples')\n",
    "    print(f'* Each sample has {f_dim} features')\n",
    "\n",
    "    # 2. get the first datapoint\n",
    "    first_feature_set = features[0, :]\n",
    "    first_target = targets[0]\n",
    "\n",
    "    print(f'* The first sample has the features:\\n{first_feature_set} '+\\\n",
    "        f'and belongs to the class {first_target}')\n",
    "\n",
    "    print('* Each datapoint can belong to any of the following classes:'+\\\n",
    "        f'\\n{classes}')\n",
    "\n",
    "    # 3. Split into train and test sets\n",
    "    (train_features, train_targets), (test_features, test_targets) =\\\n",
    "        split_train_test(features, targets, train_ratio=0.9)\n",
    "\n",
    "    train_n, test_n = train_features.shape[0], test_features.shape[0]\n",
    "    print(f'* The train set contains {train_n} samples')\n",
    "    print(f'* The test set contains {test_n} samples')\n",
    "\n",
    "using_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "087b2290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2517283950617284\n",
      "0.1497222222222222\n"
     ]
    }
   ],
   "source": [
    "# Part 1.3\n",
    "def gini_impurity(targets: np.ndarray, classes: list) -> float:\n",
    "    '''\n",
    "    Calculate:\n",
    "        i(S_k) = 1/2 * (1 - sum_i P{C_i}**2)\n",
    "    '''\n",
    "    return 0.5 * (1 - np.sum(np.power(prior(targets, classes),2)))\n",
    "\n",
    "print(gini_impurity(t_1, classes))\n",
    "print(gini_impurity(t_2, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6430be1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2109259259259259"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weighted_impurity(\n",
    "    t1: np.ndarray,\n",
    "    t2: np.ndarray,\n",
    "    classes: list\n",
    ") -> float:\n",
    "    '''\n",
    "    Given targets of two branches, return the weighted\n",
    "    sum of gini branch impurities\n",
    "    '''\n",
    "    g1 = gini_impurity(t1, classes)\n",
    "    g2 = gini_impurity(t2, classes)\n",
    "    n = t1.shape[0] + t2.shape[0]\n",
    "    \n",
    "    return (len(t1)*g1)/n + (len(t2)*g2)/n\n",
    "\n",
    "print(weighted_impurity(t_1, t_2, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5ff1f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2109259259259259\n"
     ]
    }
   ],
   "source": [
    "# Part 1.5\n",
    "def total_gini_impurity(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    classes: list,\n",
    "    split_feature_index: int,\n",
    "    theta: float\n",
    ") -> float:\n",
    "    '''\n",
    "    Calculate the gini impurity for a split on split_feature_index\n",
    "    for a given dataset of features and targets.\n",
    "    '''\n",
    "    (f_1, t_1), (f_2, t_2) = split_data(features, targets, split_feature_index, theta)\n",
    "    return weighted_impurity(t_1, t_2, classes)\n",
    "\n",
    "print(total_gini_impurity(features, targets, classes, 2, 4.65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f2c4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.16666666666666666, 2, 1.9516129032258065)\n"
     ]
    }
   ],
   "source": [
    "# Part 1.6\n",
    "def brute_best_split(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    classes: list,\n",
    "    num_tries: int\n",
    ") -> Union[float, int, float]:\n",
    "    '''\n",
    "    Find the best split for the given data. Test splitting\n",
    "    on each feature dimension num_tries times.\n",
    "\n",
    "    Return the lowest gini impurity, the feature dimension and\n",
    "    the threshold\n",
    "    '''\n",
    "    best_gini, best_dim, best_theta = float(\"inf\"), None, None\n",
    "    # iterate feature dimensions\n",
    "    for i in range(features.shape[1]):\n",
    "        # create the thresholds\n",
    "        row = features[:,i]\n",
    "        thetas = np.linspace(np.min(row), np.max(row),num_tries+2)[1:-1]\n",
    "        # iterate thresholds\n",
    "        for theta in thetas:\n",
    "            gini = total_gini_impurity(features, targets, classes, i, theta)\n",
    "            if gini < best_gini:\n",
    "                best_gini = gini\n",
    "                best_dim = i\n",
    "                best_theta = theta\n",
    "    return best_gini, best_dim, best_theta\n",
    "\n",
    "print(brute_best_split(features, targets, classes, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21decf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisTreeTrainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        features: np.ndarray,\n",
    "        targets: np.ndarray,\n",
    "        classes: list = [0, 1, 2],\n",
    "        train_ratio: float = 0.8\n",
    "    ):\n",
    "        '''\n",
    "        train_ratio: The ratio of the Iris dataset that will\n",
    "        be dedicated to training.\n",
    "        '''\n",
    "        (self.train_features, self.train_targets),\\\n",
    "            (self.test_features, self.test_targets) =\\\n",
    "            split_train_test(features, targets, train_ratio)\n",
    "\n",
    "        self.classes = classes\n",
    "        self.tree = DecisionTreeClassifier()\n",
    "\n",
    "    def train(self):\n",
    "        ...\n",
    "\n",
    "    def accuracy(self):\n",
    "        ...\n",
    "\n",
    "    def plot(self):\n",
    "        ...\n",
    "\n",
    "    def plot_progress(self):\n",
    "        # Independent section\n",
    "        # Remove this method if you don't go for independent section.\n",
    "        ...\n",
    "\n",
    "    def guess(self):\n",
    "        ...\n",
    "\n",
    "    def confusion_matrix(self):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f7c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
