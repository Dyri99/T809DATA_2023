{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3060e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Dýrmundur Helgi R. Óskarsson\n",
    "# Date: 20.9.2023\n",
    "# Project: 05 Classification\n",
    "# Acknowledgements: Einar Óskar & Torfi Tímóteus\n",
    "#\n",
    "\n",
    "\n",
    "from tools import load_iris, split_train_test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7528c027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.971875 3.3875   1.434375 0.246875]\n"
     ]
    }
   ],
   "source": [
    "# Section 1.1\n",
    "\n",
    "def mean_of_class(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    selected_class: int\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the mean of a selected class given all features\n",
    "    and targets in a dataset\n",
    "    '''\n",
    "    class_mean = np.mean(features[targets == selected_class], axis=0)\n",
    "    \n",
    "    return class_mean\n",
    "   \n",
    "\n",
    "#features, targets, classes = load_iris()\n",
    "#(train_features, train_targets), (test_features, test_targets) = split_train_test(features, targets, train_ratio = 0.6)\n",
    "\n",
    "#print(mean_of_class(train_features, train_targets, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06594c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13563508 0.11673387 0.0174496  0.01523185]\n",
      " [0.11673387 0.17016129 0.01141129 0.01479839]\n",
      " [0.0174496  0.01141129 0.03265121 0.00478831]\n",
      " [0.01523185 0.01479839 0.00478831 0.00966734]]\n"
     ]
    }
   ],
   "source": [
    "# Section 1.2\n",
    "\n",
    "def covar_of_class(\n",
    "    features: np.ndarray,\n",
    "    targets: np.ndarray,\n",
    "    selected_class: int\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Estimate the covariance of a selected class given all\n",
    "    features and targets in a dataset\n",
    "    '''\n",
    "    class_cov = np.cov(features[targets == selected_class], rowvar=False)\n",
    "    \n",
    "    return class_cov\n",
    "\n",
    "#print(covar_of_class(train_features, train_targets, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211b361a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5183032809117973\n"
     ]
    }
   ],
   "source": [
    "# Section 1.3\n",
    "\n",
    "def likelihood_of_class(\n",
    "    feature: np.ndarray,\n",
    "    class_mean: np.ndarray,\n",
    "    class_covar: np.ndarray\n",
    ") -> float:\n",
    "    '''\n",
    "    Estimate the likelihood that a sample is drawn\n",
    "    from a multivariate normal distribution, given the mean\n",
    "    and covariance of the distribution.\n",
    "    '''\n",
    "    mvn = multivariate_normal(class_mean, class_covar)\n",
    "    likelihood = mvn.pdf(feature)\n",
    "    \n",
    "    return likelihood\n",
    "    \n",
    "#class_mean = mean_of_class(train_features, train_targets, 0)\n",
    "#class_cov = covar_of_class(train_features, train_targets, 0)\n",
    "#print(likelihood_of_class(test_features[0, :], class_mean, class_cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f0679d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.87608368e-116 5.15389915e-002 1.58685993e-001]\n",
      " [3.20814672e-085 1.73314212e+000 5.37011170e-004]\n",
      " [8.36399009e-052 5.38397718e-001 3.70323661e-005]\n",
      " [7.50380637e+000 5.00557693e-026 2.70558330e-036]\n",
      " [4.14973303e-233 6.10806507e-008 1.37023660e-001]\n",
      " [7.38275800e-201 1.62783390e-007 1.26101112e+000]\n",
      " [9.23046883e-066 2.38147431e+000 6.08721596e-003]\n",
      " [1.56841031e-001 1.15485566e-027 5.45846749e-037]\n",
      " [9.13355510e-085 2.13350936e-001 4.28732288e-003]\n",
      " [1.44476128e-001 2.68430751e-020 2.97226225e-027]\n",
      " [1.28895416e-064 7.05249278e-001 2.57877366e-004]\n",
      " [1.47788578e-091 2.24531842e+000 2.61812533e-002]\n",
      " [1.96226171e-146 7.85084293e-004 1.22200436e+000]\n",
      " [3.96659593e+000 3.96078730e-020 1.25327138e-028]\n",
      " [6.05800285e-089 7.99447306e-001 3.08665358e-002]\n",
      " [4.89829838e-139 2.53660019e-004 7.26346852e-001]\n",
      " [6.44328126e-001 5.58592186e-036 4.87549765e-049]\n",
      " [1.09729849e+001 1.19724133e-025 2.22561472e-035]\n",
      " [1.37118361e-189 9.80458836e-005 4.59105828e-001]\n",
      " [1.11349489e-095 1.74753149e+000 1.37571384e-003]\n",
      " [2.66242306e-094 1.95233437e+000 1.05805229e-002]\n",
      " [1.69133824e-104 1.15662856e+000 1.57114052e-003]\n",
      " [6.03435155e-064 2.40810663e+000 1.44329266e-004]\n",
      " [1.44474898e-073 2.60369401e+000 1.74025622e-004]\n",
      " [1.20236664e-096 2.95612008e-002 3.72832117e-003]\n",
      " [4.32192978e+000 1.66898030e-022 8.92866920e-033]\n",
      " [2.06586144e-229 4.28995621e-007 3.14711635e-001]\n",
      " [6.96524843e+000 4.29347941e-018 2.27304250e-026]\n",
      " [1.09592313e+001 1.03266092e-020 1.14776244e-029]\n",
      " [5.73456667e+000 1.97408718e-021 1.07477945e-029]\n",
      " [1.92504371e-080 7.88868868e-001 2.94736173e-005]\n",
      " [2.32729868e-136 9.18950803e-005 2.05618961e-001]\n",
      " [2.89422967e+000 2.19442589e-020 5.13695575e-029]\n",
      " [7.44417083e-073 3.93958270e+000 6.43708765e-004]\n",
      " [4.68935078e-067 7.47571860e-001 9.16758591e-003]\n",
      " [4.39541860e+000 4.63302886e-018 5.04160207e-026]\n",
      " [2.05258340e-033 5.75230598e-002 6.99554595e-007]\n",
      " [3.61559418e-057 3.37338592e+000 2.26298467e-004]\n",
      " [1.81146721e-074 2.80805463e-001 1.08738534e-002]\n",
      " [1.02160481e-269 4.80945908e-013 9.41736028e-003]\n",
      " [5.73571703e-114 4.03119484e-001 2.05529483e-001]\n",
      " [4.75969803e+000 1.20681194e-027 1.62908598e-038]\n",
      " [1.16437230e-052 1.73358877e+000 3.32227906e-004]\n",
      " [6.94724782e-002 2.06287427e-012 1.30566698e-021]\n",
      " [1.71648517e+000 6.39579765e-029 1.35718653e-040]\n",
      " [1.44919486e-225 5.63324229e-012 9.29983542e-002]\n",
      " [7.28570030e+000 1.31732658e-018 5.27597610e-028]\n",
      " [6.91898823e+000 2.91287521e-027 8.77027295e-038]\n",
      " [2.23633639e-224 6.93475831e-010 2.03951032e-001]\n",
      " [6.59159472e+000 7.83962464e-017 3.53340034e-026]\n",
      " [8.14493184e-001 7.46875548e-021 1.21501116e-028]\n",
      " [3.25566174e-195 1.61949137e-009 3.97914953e-001]\n",
      " [8.95774135e+000 7.40170923e-020 3.94823503e-028]\n",
      " [1.95815913e-208 1.28052235e-011 6.63973217e-001]\n",
      " [4.94726470e+000 1.40773377e-016 2.95995967e-024]\n",
      " [5.80823971e-092 3.77976193e-001 1.57724879e-005]\n",
      " [7.14220265e-108 1.46051494e-004 3.27653109e-002]\n",
      " [1.96534652e-001 9.45417698e-016 1.89034683e-025]\n",
      " [3.87676161e+000 4.88336902e-023 2.28569693e-033]]\n"
     ]
    }
   ],
   "source": [
    "def maximum_likelihood(\n",
    "    train_features: np.ndarray,\n",
    "    train_targets: np.ndarray,\n",
    "    test_features: np.ndarray,\n",
    "    classes: list\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Calculate the maximum likelihood for each test point in\n",
    "    test_features by first estimating the mean and covariance\n",
    "    of all classes over the training set.\n",
    "\n",
    "    You should return\n",
    "    a [test_features.shape[0] x len(classes)] shaped numpy\n",
    "    array\n",
    "    '''\n",
    "    means, covs = [], []\n",
    "    for class_label in classes:\n",
    "        class_mean = mean_of_class(train_features, train_targets, class_label)\n",
    "        class_cov = covar_of_class(train_features, train_targets, class_label)\n",
    "        \n",
    "        means.append(class_mean), covs.append(class_cov)\n",
    "    likelihoods = []\n",
    "    for i in range(test_features.shape[0]):\n",
    "        likelihood = []\n",
    "        for j in range(len(classes)):\n",
    "            likelihood.append(likelihood_of_class(train_features[i], means[j], covs[j]))\n",
    "        likelihoods.append(likelihood)\n",
    "    return np.array(likelihoods)\n",
    "\n",
    "#print(maximum_likelihood(train_features, train_targets, test_features, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ed376d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241c0845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 0 2 2 1 0 1 0 1 1 2 0 1 2 0 0 2 1 1 1 1 1 1 0 2 0 0 0 1 2 0 1 1 0 1\n",
      " 1 1 2 1 0 1 0 0 2 0 0 2 0 0 2 0 2 0 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Section 1.5\n",
    "\n",
    "def predict(likelihoods: np.ndarray):\n",
    "    '''\n",
    "    Given an array of shape [num_datapoints x num_classes]\n",
    "    make a prediction for each datapoint by choosing the\n",
    "    highest likelihood.\n",
    "\n",
    "    You should return a [likelihoods.shape[0]] shaped numpy\n",
    "    array of predictions, e.g. [0, 1, 0, ..., 1, 2]\n",
    "    '''\n",
    "    return np.argmax(likelihoods, axis=1)\n",
    "\n",
    "#likelihoods = maximum_likelihood(train_features, train_targets, test_features, classes)\n",
    "#print(predict(likelihoods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c19127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 0 2 2 1 0 1 0 1 1 2 0 1 2 0 0 2 1 1 1 1 1 1 0 2 0 0 0 1 2 0 1 1 0 1\n",
      " 1 1 2 1 0 1 0 0 2 0 0 2 0 0 2 0 2 0 1 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Section 2.1\n",
    "\n",
    "def maximum_aposteriori(\n",
    "    train_features: np.ndarray,\n",
    "    train_targets: np.ndarray,\n",
    "    test_features: np.ndarray,\n",
    "    classes: list\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Calculate the maximum a posteriori for each test point in\n",
    "    test_features by first estimating the mean and covariance\n",
    "    of all classes over the training set.\n",
    "\n",
    "    You should return\n",
    "    a [test_features.shape[0] x len(classes)] shaped numpy\n",
    "    array\n",
    "    '''\n",
    "    means, covs, priors = [], [], []\n",
    "    length_features = len(train_features)\n",
    "    for class_label in classes:\n",
    "        class_mean = mean_of_class(train_features, train_targets, class_label)\n",
    "        class_cov = covar_of_class(train_features, train_targets, class_label)\n",
    "        prior = len(train_features[train_targets == class_label]) / length_features\n",
    "        \n",
    "        means.append(class_mean), covs.append(class_cov), priors.append(prior)\n",
    "    likelihoods = []\n",
    "    for i in range(test_features.shape[0]):\n",
    "        likelihood = []\n",
    "        for j in range(len(classes)):\n",
    "            likelihood.append((likelihood_of_class(train_features[i], means[j], covs[j])) * priors[j])\n",
    "        likelihoods.append(likelihood)\n",
    "    return np.array(likelihoods)\n",
    "\n",
    "#posteriors = maximum_aposteriori(train_features, train_targets, test_features, classes)\n",
    "#print(posteriors)\n",
    "\n",
    "#predictions = predict(posteriors)\n",
    "#print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbf1632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2.2\n",
    "\n",
    "#predictions = predict(likelihoods)\n",
    "#predictions = predict(posteriors)\n",
    "\n",
    "#print(train_targets[0:len(predictions)])\n",
    "#count=0\n",
    "#for i, tt in enumerate(train_targets[0:len(predictions)]):\n",
    "#    if tt==predictions[i]:\n",
    "#        count+=1\n",
    "#print(count/len(predictions))\n",
    "\n",
    "#length = len(classes)\n",
    "#confusion_matrix = np.zeros((length, length), dtype='int')\n",
    "\n",
    "#for i in range(len(predictions)):\n",
    "#    correct = train_targets[i]\n",
    "#    guess = predictions[i]\n",
    "#    confusion_matrix[guess][correct] += 1\n",
    "    \n",
    "#print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044eec72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
